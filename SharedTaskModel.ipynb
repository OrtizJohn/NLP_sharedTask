{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a0cac7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7371e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0afd5",
   "metadata": {},
   "source": [
    "Prepping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f257209f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A01001', 'Entrapment should be legalized', 'in favor of', \"if entrapment can serve to more easily capture wanted criminals, then why shouldn't it be legal?\"]\n",
      "['A01001', 'Entrapment should be legalized', 'in favor of', \"if entrapment can serve to more easily capture wanted criminals, then why shouldn't it be legal?\"]\n",
      "['A01001', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['A26004', 'We should end affirmative action', 'against', 'affirmative action helps with employment equity.']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"data/arguments-training.tsv\", 'r', encoding='utf8')\n",
    "x_train = [line.strip().split('\\t') for line in file.readlines()[1:]]\n",
    "file.close()\n",
    "print(x_train[0])\n",
    "\n",
    "file = open(\"data/labels-training.tsv\", 'r', encoding='utf8')\n",
    "y_train = [line.strip().split('\\t') for line in file.readlines()[1:]]\n",
    "file.close()\n",
    "\n",
    "file = open(\"data/arguments-validation.tsv\", 'r', encoding='utf8')\n",
    "x_valid = [line.strip().split('\\t') for line in file.readlines()[1:]]\n",
    "file.close()\n",
    "print(x_valid[0])\n",
    "file = open(\"data/labels-validation.tsv\", 'r', encoding='utf8')\n",
    "y_valid = [line.strip().split('\\t') for line in file.readlines()[1:]]\n",
    "file.close()\n",
    "print(y_valid[0])\n",
    "file = open(\"data/arguments-test.tsv\", 'r', encoding='utf8')\n",
    "x_test = [line.strip().split('\\t') for line in file.readlines()[1:]]\n",
    "file.close()\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ae5af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', Entrapment, should, be, legalized, '<CON>', if, entrapment, can, serve, to, more, easily, capture, wanted, criminals, ,, then, why, should, n't, it, be, legal, ?, '<EOS>'] ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "x_train size:  5220  - x_train size:  5220\n",
      "___________________\n",
      "['<SOS>', Entrapment, should, be, legalized, '<CON>', if, entrapment, can, serve, to, more, easily, capture, wanted, criminals, ,, then, why, should, n't, it, be, legal, ?, '<EOS>'] ['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "x_valid size:  1896  - y_valid size:  1896\n",
      "_______________\n",
      "['<SOS>', We, should, end, affirmative, action, '<CON>', affirmative, action, helps, with, employment, equity, ., '<EOS>']\n",
      "xTest size:  1576\n"
     ]
    }
   ],
   "source": [
    "#Tokenize, conjoin strings, and add special tokens, remove item ids from labels\n",
    "import spacy\n",
    "\n",
    "def tokenize(text, labels=None):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    args = []\n",
    "    labs = []\n",
    "    if(labels != None):\n",
    "        for arg, lab in zip(text, labels):\n",
    "            if arg[3] == 'in favor of':\n",
    "                sep = ['<PRO>']\n",
    "            else:\n",
    "                sep = ['<CON>']\n",
    "            item = ['<SOS>'] + list(nlp(arg[1])) + sep + list(nlp(arg[3])) + ['<EOS>']\n",
    "            args.append(item)\n",
    "            labs.append(lab[1:20])\n",
    "    else:\n",
    "        for arg in text:\n",
    "            if arg[3] == 'in favor of':\n",
    "                sep = ['<PRO>']\n",
    "            else:\n",
    "                sep = ['<CON>']\n",
    "            item = ['<SOS>'] + list(nlp(arg[1])) + sep + list(nlp(arg[3])) + ['<EOS>']\n",
    "            args.append(item)\n",
    "\n",
    "    return args, labs\n",
    "    \n",
    "def tokenize_allData(x_train,y_train,x_valid,y_valid,x_test):\n",
    "    x_train, y_train = tokenize(x_train, y_train)\n",
    "    x_valid, y_valid = tokenize(x_valid,y_valid)\n",
    "    x_test, _ = tokenize(x_test)\n",
    "    print(x_train[0], y_train[0])\n",
    "    print(\"x_train size: \",len(x_train),\" - x_train size: \",len(y_train))\n",
    "    print(\"___________________\")\n",
    "    print(x_valid[0], y_valid[0])\n",
    "    print(\"x_valid size: \",len(x_valid),\" - y_valid size: \",len(y_valid))\n",
    "    print(\"_______________\")\n",
    "    print(x_test[0])\n",
    "    print(\"xTest size: \", len(x_test))\n",
    "    return x_train,y_train,x_valid,y_valid,x_test\n",
    "x_train,y_train,x_valid,y_valid,x_test = tokenize_allData(x_train,y_train,x_valid,y_valid,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02699a90",
   "metadata": {},
   "source": [
    "## Label Selection (Which labels to use in models )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb00999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLabels_NotWanted(labels, labels_wanted):\n",
    "    newLabels=[]\n",
    "    for row in labels:\n",
    "        newRow = []\n",
    "        for i in labels_wanted:\n",
    "            newRow.append(row[i])\n",
    "        assert len(newRow) == len(labels_wanted)\n",
    "        newLabels.append(newRow)\n",
    "    return newLabels\n",
    "def removeAllEmptyLabelRows(text,labels):\n",
    "    newText=[]\n",
    "    newLabels=[]\n",
    "    for i in range(len(text)):\n",
    "        intList = [eval(j) for j in labels[i] ]\n",
    "        if(np.sum(intList)!=0):\n",
    "            newText.append(text[i])\n",
    "            newLabels.append(labels[i])\n",
    "      #else:\n",
    "            #print(labels[i])\n",
    "    return newText,newLabels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087c5dd",
   "metadata": {},
   "source": [
    "### Creating different labels for training on     \n",
    "    labels_starters recommended by Eval:   Self-direction: action, Achievement, Security: personal, Security: societal, Benevolence: caring, Universalism: concern.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b6877e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original items: 5220 5220\n",
      "xTest - yTest 3410 - 3410\n",
      "xValid - yValid:  1208 - 1208\n"
     ]
    }
   ],
   "source": [
    "reference_labels = {\n",
    "    \"Self-direction: thought\": 0,\n",
    "    \"Self-direction: action\": 1,\t\n",
    "    \"Stimulation\": 2,\n",
    "    \"Hedonism\": 3,\n",
    "    \"Achievement\": 4,\n",
    "    \"Power: dominance\": 5,\n",
    "    \"Power: resources\": 6,\n",
    "    \"Face\": 7,\t\n",
    "    \"Security: personal\": 8,\n",
    "    \"Security: societal\": 9,\n",
    "    \"Tradition\": 10,\n",
    "    \"Conformity: rules\": 11,\n",
    "    \"Conformity: interpersonal\": 12,\n",
    "    \"Humility\": 13,\t\n",
    "    \"Benevolence: caring\": 14,\n",
    "    \"Benevolence: dependability\": 15,\t\n",
    "    \"Universalism: concern\": 16,\t\n",
    "    \"Universalism: nature\": 17,\t\n",
    "    \"Universalism: tolerance\": 18,\n",
    "    \"Universalism: objectivity\": 19\n",
    "}\n",
    "\n",
    "recommended_categories = [1, 4, 8, 9, 14, 16]\n",
    "print(\"Number of original items:\",len(x_train), len(y_train))\n",
    "labels_starters = removeLabels_NotWanted(y_train, recommended_categories)\n",
    "x_train_trimmed, labels_starters_train = removeAllEmptyLabelRows(x_train, labels_starters)\n",
    "print(\"xTest - yTest\", len(x_train_trimmed),\"-\",len(labels_starters_train))\n",
    "labels_starters_valid = removeLabels_NotWanted(y_valid, recommended_categories)\n",
    "x_valid_trimmed, labels_starters_valid = removeAllEmptyLabelRows(x_valid, labels_starters_valid)\n",
    "print(\"xValid - yValid: \", len(x_valid_trimmed),\"-\",len(labels_starters_valid))\n",
    "starters_dict = {\n",
    "    \"Self-direction: action\":0,\n",
    "    \"Achievement\": 1,\n",
    "    \"Security: personal\": 2,\n",
    "    \"Security: societal\": 3,\n",
    "    \"Benevolence: caring\": 4,\n",
    "    \"Universalism: concern\": 16\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a61ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsecurity = [8, 9]\\nprint(\"Number of original items:\",len(x_train), len(y_train))\\nlabels_security = removeLabels_NotWanted(y_train, security)\\nx_train_trimmed, labels_security_train = removeAllEmptyLabelRows(x_train, labels_security)\\nprint(\"Number of items with one of the desired labels:\",len(x_train_trimmed),\" - \", len(labels_security_train))\\nlabels_security_valid = removeLabels_NotWanted(y_valid, security)\\nx_valid_trimmed, labels_security_valid = removeAllEmptyLabelRows(x_valid, labels_security_valid)\\n\\nsecurity_dict = {\\n    \"Security: personal\": 0,\\n    \"Security: societal\": 1\\n}'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "security = [8, 9]\n",
    "print(\"Number of original items:\",len(x_train), len(y_train))\n",
    "labels_security = removeLabels_NotWanted(y_train, security)\n",
    "x_train_trimmed, labels_security_train = removeAllEmptyLabelRows(x_train, labels_security)\n",
    "print(\"Number of items with one of the desired labels:\",len(x_train_trimmed),\" - \", len(labels_security_train))\n",
    "labels_security_valid = removeLabels_NotWanted(y_valid, security)\n",
    "x_valid_trimmed, labels_security_valid = removeAllEmptyLabelRows(x_valid, labels_security_valid)\n",
    "\n",
    "security_dict = {\n",
    "    \"Security: personal\": 0,\n",
    "    \"Security: societal\": 1\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bb90d",
   "metadata": {},
   "source": [
    "## Create PT3 Label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bc45830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makePT3Labels(allClassLabels):\n",
    "    PT3LabelsDict = {}\n",
    "    PT3Labels_idx = []\n",
    "    PT3Labels_vects = []\n",
    "    label=0\n",
    "    for row in allClassLabels:\n",
    "        row_lab = [key for key, value in PT3LabelsDict.items() if value == row]\n",
    "        if row_lab:\n",
    "            PT3Labels_idx.append(row_lab[0])\n",
    "        else:\n",
    "            PT3LabelsDict[label] = row\n",
    "            PT3Labels_idx.append(label)\n",
    "            label += 1\n",
    "    # for row in PT3Labels_idx:\n",
    "    #     label_vect = [0]*len(PT3LabelsDict)\n",
    "    #     label_vect[row] = 1\n",
    "    #     PT3Labels_vects.append(label_vect)\n",
    "\n",
    "    return PT3Labels_idx, PT3LabelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64791c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT3 ySize-  3410\n",
      "PT3 ySizeValid-  1208\n",
      "Number of new combination labels: 47\n"
     ]
    }
   ],
   "source": [
    "PT3LabelsTrain, PT3Dict = makePT3Labels(labels_starters_train)\n",
    "\n",
    "\n",
    "#PT3Labels_idx = []\n",
    "PT3LabelsValid = []\n",
    "label=0\n",
    "for row in labels_starters_valid:\n",
    "    row_lab = [key for key, value in PT3Dict.items() if value == row]\n",
    "    if row_lab:\n",
    "        PT3LabelsValid.append(row_lab[0])\n",
    "    else:\n",
    "        PT3Dict[label] = row\n",
    "        PT3LabelsValid.append(label)\n",
    "        label += 1\n",
    "# for row in PT3Labels_idx:\n",
    "#     label_vect = [0]*len(PT3Dict)\n",
    "#     label_vect[row] = 1\n",
    "#     PT3LabelsValid.append(label_vect)\n",
    "print(\"PT3 ySize- \",len(PT3LabelsTrain))\n",
    "print(\"PT3 ySizeValid- \",len(PT3LabelsValid))\n",
    "print(\"Number of new combination labels:\", len(PT3Dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e2edb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PT3LabelsTrain, PT3Dict = makePT3Labels(labels_security_train)\\n\\n\\n#PT3Labels_idx = []\\nPT3LabelsValid = []\\nlabel=0\\nfor row in labels_security_valid:\\n    row_lab = [key for key, value in PT3Dict.items() if value == row]\\n    if row_lab:\\n        PT3LabelsValid.append(row_lab[0])\\n    else:\\n        PT3Dict[label] = row\\n        PT3LabelsValid.append(label)\\n        label += 1\\n# for row in PT3Labels_idx:\\n#     label_vect = [0]*len(PT3Dict)\\n#     label_vect[row] = 1\\n#     PT3LabelsValid.append(label_vect)\\n\\nprint(\"Number of new combination labels:\", len(PT3Dict))\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncommment to run PT3 for labels = security\n",
    "\"\"\"PT3LabelsTrain, PT3Dict = makePT3Labels(labels_security_train)\n",
    "\n",
    "\n",
    "#PT3Labels_idx = []\n",
    "PT3LabelsValid = []\n",
    "label=0\n",
    "for row in labels_security_valid:\n",
    "    row_lab = [key for key, value in PT3Dict.items() if value == row]\n",
    "    if row_lab:\n",
    "        PT3LabelsValid.append(row_lab[0])\n",
    "    else:\n",
    "        PT3Dict[label] = row\n",
    "        PT3LabelsValid.append(label)\n",
    "        label += 1\n",
    "# for row in PT3Labels_idx:\n",
    "#     label_vect = [0]*len(PT3Dict)\n",
    "#     label_vect[row] = 1\n",
    "#     PT3LabelsValid.append(label_vect)\n",
    "\n",
    "print(\"Number of new combination labels:\", len(PT3Dict))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac4a03",
   "metadata": {},
   "source": [
    "## Get PT4 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e1050ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates two dictionaries, one with positive instances for each class\n",
    "#and one for negative instances for each class\n",
    "def makePT4Labels(allClassLabels):\n",
    "    PT4LabelsPos = {}\n",
    "    PT4LabelsNeg = {}\n",
    "    \n",
    "    for i in range(len(allClassLabels)):\n",
    "        PT4LabelsPos[i] = []\n",
    "        PT4LabelsNeg[i] = []\n",
    "\n",
    "    for row in allClassLabels:\n",
    "        label_idx = 0\n",
    "        for label in row:\n",
    "            if label == '0':\n",
    "                PT4LabelsPos[label_idx].append(0)\n",
    "                PT4LabelsNeg[label_idx].append(1)\n",
    "            if label == '1':\n",
    "                PT4LabelsPos[label_idx].append(1)\n",
    "                PT4LabelsNeg[label_idx].append(0)\n",
    "            label_idx += 1\n",
    "    assert len(PT4LabelsPos[0]) == len(PT4LabelsNeg[0]) == len(allClassLabels)\n",
    "\n",
    "    return PT4LabelsPos, PT4LabelsNeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42227642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5220 5220\n"
     ]
    }
   ],
   "source": [
    "PT4LabelsPos, PT4LabelsNeg = makePT4Labels(labels_starters)\n",
    "print(len(PT4LabelsPos), len(PT4LabelsNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1ad01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(PT4LabelsPos.update(PT4LabelsNeg))\n",
    "#PT4LabelsPos.update(PT4LabelsNeg)\n",
    "#PT4LabelsTrain = PT4LabelsPos.copy()\n",
    "#(len(PT4LabelsTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660d97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ebdc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SPECIAL_TOKENS = ['<UNK>', '<PAD>', '<SOS>', '<EOS>', '<PRO>', '<CON>']\n",
    "vocab = sorted(set([str(w) for ws in list(x_train_trimmed) + [SPECIAL_TOKENS] for w in ws]))\n",
    "embeddings_path = '../glove.twitter.27B.200d.txt'\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def read_pretrained_embeddings(\n",
    "    embeddings_path: str,\n",
    "    vocab\n",
    ") -> Tuple[Dict[str, int], torch.FloatTensor]:\n",
    "    \"\"\"Read the embeddings matrix and make a dict hashing each word.\n",
    "\n",
    "    Args:\n",
    "        embeddings_path (str): _description_\n",
    "        vocab_path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], torch.FloatTensor]: _description_\n",
    "    \"\"\"\n",
    "    word2i = {}\n",
    "    vectors = []\n",
    "    \n",
    "    print(f\"Reading embeddings from {embeddings_path}...\")\n",
    "    with open(embeddings_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            word, *weights = line.rstrip().split(\" \")\n",
    "            \n",
    "            if word in vocab:\n",
    "                word2i[word] = i\n",
    "                i += 1\n",
    "                w_weights = [float(i) for i in weights]\n",
    "                vectors.append(w_weights)\n",
    "\n",
    "        vectors = torch.FloatTensor(vectors)\n",
    "\n",
    "    return word2i, vectors\n",
    "\n",
    "def get_oovs(vocab, word2i: Dict[str, int]) -> List[str]:\n",
    "    \"\"\"Find the vocab items that do not exist in the glove embeddings (in word2i).\n",
    "    Return the List of such (unique) words.\n",
    "\n",
    "    Args:\n",
    "        vocab_path: List of batches of sentences.\n",
    "        word2i (Dict[str, int]): _description_\n",
    "\n",
    "    Returns:\n",
    "        List[str]: _description_\n",
    "    \"\"\"\n",
    "    glove_and_vocab = set(word2i.keys())\n",
    "    vocab_and_not_glove = set(vocab) - glove_and_vocab\n",
    "    return list(vocab_and_not_glove)\n",
    "\n",
    "def initialize_new_embedding_weights(num_embeddings: int, dim: int) -> torch.FloatTensor:\n",
    "    \"\"\"xavier initialization for the embeddings of words in train, but not in gLove.\n",
    "\n",
    "    Args:\n",
    "        num_embeddings (int): _description_\n",
    "        dim (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: _description_\n",
    "    \"\"\"\n",
    "    #Initialize a num_embeddings x dim matrix with xiavier initiialization\n",
    "    return torch.FloatTensor(np.random.normal(0, dim**-0.5, size=(num_embeddings, dim)))\n",
    "    \n",
    "\n",
    "def update_embeddings(\n",
    "    glove_word2i: Dict[str, int],\n",
    "    glove_embeddings: torch.FloatTensor,\n",
    "    oovs: List[str]\n",
    ") -> Tuple[Dict[str, int], torch.FloatTensor]:\n",
    "    #Add the oov words to the dict, assigning a new index to each\n",
    "        i = len(glove_embeddings)\n",
    "        for w in oovs:\n",
    "            glove_word2i[w] = i\n",
    "            i +=1\n",
    "    #Concatenate a new row to embeddings for each oov, initialize those new rows with `intialize_new_embedding_weights`\n",
    "        new_emb = initialize_new_embedding_weights(len(oovs), len(glove_embeddings[0]))\n",
    "        cat_emb = torch.cat((glove_embeddings, new_emb), 0)\n",
    "        return (glove_word2i, cat_emb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4414327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embeddings from ../glove.twitter.27B.200d.txt...\n"
     ]
    }
   ],
   "source": [
    "glove_word2i, glove_embeddings = read_pretrained_embeddings(embeddings_path,vocab)\n",
    "oovs = get_oovs(vocab, glove_word2i)\n",
    "\n",
    "# Add the oovs from training data to the word2i encoding, and as new rows\n",
    "# to the embeddings matrix\n",
    "word2i, embeddings = update_embeddings(glove_word2i, glove_embeddings, oovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54826dfe",
   "metadata": {},
   "source": [
    "Batch Training arguments and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45e93ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def make_batches(sequences: List[List[str]], labels: List[List[int]], batch_size: int) -> (List[List[List[str]]], List[List[List[int]]]):\n",
    "    \"\"\"Yield batch_size chunks from sequences.\"\"\"\n",
    "    \n",
    "    num_batch = math.floor(len(sequences)/batch_size)\n",
    "    batched_sents = []\n",
    "    batched_labs = []\n",
    "    \n",
    "    df = pd.DataFrame(data = {\"seq\": sequences, \"lab\": labels})\n",
    "    for i in range(num_batch):\n",
    "        batch = df.sample(n=batch_size)\n",
    "        #print(\"Batch size: \",batch.shape[0])\n",
    "        this_batch_sents = []\n",
    "        this_batch_labs = []\n",
    "        for index, row in batch.iterrows():\n",
    "            sent = row['seq']\n",
    "            label = row['lab']\n",
    "            #df = df[df.seq != sent]\n",
    "            this_batch_sents.append(sent)\n",
    "            this_batch_labs.append(label)\n",
    "        df = df.drop(batch.index)\n",
    "        batched_sents.append(this_batch_sents)\n",
    "        batched_labs.append(this_batch_labs)\n",
    "        \n",
    "    return batched_sents, batched_labs\n",
    "\n",
    "\n",
    "def pad(sents, labs):\n",
    "    lengths = []\n",
    "    for sent in sents:\n",
    "        lengths.append(len(sent))\n",
    "            \n",
    "    max_length = max(lengths)\n",
    "        \n",
    "    for sent in sents:\n",
    "        n = max_length - len(sent)\n",
    "        for i in range(n):\n",
    "            sent.append(\"\")\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288ffb2",
   "metadata": {},
   "source": [
    "### Make batches for each different dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3c96f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410 3410\n",
      "1208 1208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#batching train\\nPT4_batches_train = []\\nPT4_batched_sents, PT4_batched_labs = make_batches(x_train_trimmed, PT4LabelsTrain, batch_size)\\nfor batch in PT4_batched_sents:\\n    pad_batch = pad(batch, PT4_batched_labs_valid)\\n    PT4_batches_train.append(pad_batch)\\n#batching valid\\nPT4_batches_valid = []\\nPT4_batched_sents_valid, PT4_batched_labs_valid = make_batches(x_valid_trimmed, PT4LabelsValid, batch_size)\\nfor batch in PT4_batched_sents_valid:\\n    pad_batch = pad(batch, PT4_batched_labs_valid)\\n    PT4_batches_valid.append(pad_batch)\\n    '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your preferred batch size\n",
    "batch_size = 8\n",
    "\n",
    "#_________PT3________#\n",
    "# We make batches now and use those.\n",
    "PT3_batches_train = []\n",
    "# Note: Labels need to be batched in the same way to ensure\n",
    "# We have train sentence and label batches lining up.\n",
    "print(len(x_train_trimmed),len(PT3LabelsTrain))\n",
    "PT3_batched_sents, PT3_batched_labs = make_batches(x_train_trimmed, PT3LabelsTrain, batch_size)\n",
    "for batch in PT3_batched_sents:\n",
    "    pad_batch = pad(batch, PT3_batched_labs)\n",
    "    PT3_batches_train.append(pad_batch)\n",
    "    \n",
    "print(len(x_valid_trimmed),len(PT3LabelsValid))\n",
    "PT3_batches_valid = []\n",
    "PT3_batched_sents_valid, PT3_batched_labs_valid = make_batches(x_valid_trimmed, PT3LabelsValid, batch_size)\n",
    "for batch in PT3_batched_sents_valid:\n",
    "    pad_batch = pad(batch, PT3_batched_labs_valid)\n",
    "    PT3_batches_valid.append(pad_batch)\n",
    "   \n",
    "#________PT4_________#\n",
    "\"\"\"\n",
    "#batching train\n",
    "PT4_batches_train = []\n",
    "PT4_batched_sents, PT4_batched_labs = make_batches(x_train_trimmed, PT4LabelsTrain, batch_size)\n",
    "for batch in PT4_batched_sents:\n",
    "    pad_batch = pad(batch, PT4_batched_labs_valid)\n",
    "    PT4_batches_train.append(pad_batch)\n",
    "#batching valid\n",
    "PT4_batches_valid = []\n",
    "PT4_batched_sents_valid, PT4_batched_labs_valid = make_batches(x_valid_trimmed, PT4LabelsValid, batch_size)\n",
    "for batch in PT4_batched_sents_valid:\n",
    "    pad_batch = pad(batch, PT4_batched_labs_valid)\n",
    "    PT4_batches_valid.append(pad_batch)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d8455ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSizeOfPT_Batched(sents,labs):\n",
    "    sumS = 0\n",
    "    sumL = 0 \n",
    "    for sent in sents:\n",
    "        sumS+= len(sent)\n",
    "    for lab in labs:\n",
    "        sumL += len(lab)\n",
    "    return sumS,sumL\n",
    "    \n",
    "#print(\"PT4 Train Sentences - Labels\",getSizeOfPT_Batched(PT4_batched_sents,PT4_batched_labs))\n",
    "#print(\"PT4 Valid Sentences - Labels\",getSizeOfPT_Batched(PT4_batched_sents_valid,PT4_batched_labs_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e413d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ValuesClassifier(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "    output_size: int, \n",
    "    hidden_size: int,\n",
    "    embeddings_tensor: torch.FloatTensor,\n",
    "    pad_idx: int,\n",
    "    dropout_val: float = 0.3,\n",
    "    input_dim: int = 200,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "        self.embeddings = torch.nn.Embedding.from_pretrained(embeddings_tensor, freeze = False, padding_idx = pad_idx)\n",
    "        self.dropout_val = dropout_val\n",
    "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_val, inplace=False)\n",
    "        self.pad_idx = pad_idx\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            self.input_dim,\n",
    "            self.hidden_size,\n",
    "            num_layers=2,\n",
    "            dropout=dropout_val,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (torch.Tensor): The batch size x sequence length tensor of input tokens\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the embedding for each input symbol\n",
    "        embedded = self.embeddings(symbols)\n",
    "        embedded = self.dropout_layer(embedded)\n",
    "        # Packs embedded source symbols into a PackedSequence.\n",
    "        # This is an optimization when using padded sequences with an LSTM\n",
    "        lens = (symbols != self.pad_idx).sum(dim=1).to(\"cpu\")\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lens, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        # -> batch_size x seq_len x encoder_dim, (h0, c0).\n",
    "        packed_outs, (H, C) = self.lstm(packed)\n",
    "        encoded, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_outs,\n",
    "            batch_first=True,\n",
    "            padding_value=self.pad_idx,\n",
    "            total_length=None,\n",
    "        )\n",
    "        # Now we have the representation of eahc token encoded by the LSTM.\n",
    "        encoded, (H, C) = self.lstm(embedded)\n",
    "        \n",
    "        # This part looks tricky. All we are doing is getting a tensor\n",
    "        # That indexes the last non-PAD position in each tensor in the batch.\n",
    "        last_enc_out_idxs = lens - 1\n",
    "        # -> B x 1 x 1.\n",
    "        last_enc_out_idxs = last_enc_out_idxs.view([encoded.size(0)] + [1, 1])\n",
    "        # -> 1 x 1 x encoder_dim. This indexes the last non-padded dimension.\n",
    "        last_enc_out_idxs = last_enc_out_idxs.expand(\n",
    "            [-1, -1, encoded.size(-1)]\n",
    "        )\n",
    "        # Get the final hidden state in the LSTM\n",
    "        last_hidden = torch.gather(encoded, 1, last_enc_out_idxs)\n",
    "        return last_hidden\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        output = self.relu(output)\n",
    "        output = self.classifier(output)\n",
    "        return self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b393149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these functions to encode your batches before you call the train loop.\n",
    "\n",
    "def encode_sentences(batch: List[List[str]], word2i: Dict[str, int]) -> torch.LongTensor:\n",
    "    \"\"\"Encode the tokens in each sentence in the batch with a dictionary\n",
    "\n",
    "    Args:\n",
    "        batch (List[List[str]]): The padded and tokenized batch of sentences.\n",
    "        word2i (Dict[str, int]): The encoding dictionary.\n",
    "\n",
    "    Returns:\n",
    "        torch.LongTensor: The tensor of encoded sentences.\n",
    "    \"\"\"\n",
    "    UNK_IDX = word2i[\"<UNK>\"]\n",
    "    tensors = []\n",
    "    for sent in batch:\n",
    "        tensors.append(torch.LongTensor([word2i.get(w, UNK_IDX) for w in sent]))\n",
    "        \n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "def encode_labels(labels: List[int]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    return torch.LongTensor([int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb5f3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For making predictions at test time\n",
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    return list(torch.argmax(logits, axis=2).squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1da0fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import logical_and, sum as t_sum\n",
    "\n",
    "\n",
    "def precision(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(pred_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(true_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    which_label: int\n",
    "):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "    if P and R:\n",
    "        return 2*P*R/(P+R)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def macro_f1(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    possible_labels: List[int]\n",
    "):\n",
    "    scores = [f1_score(predicted_labels, true_labels, l) for l in possible_labels]\n",
    "    # Macro, so we take the uniform avg.\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42076322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "    possible_labels,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.NLLLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        print(\"Working on epoch\", i)\n",
    "        for features, labels in tqdm.tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "            loss = loss_func(preds, labels)\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm.tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "\n",
    "        dev_f1 = macro_f1(all_preds, all_labels, possible_labels)\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 10\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.00001\n",
    "hidden_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "#encode\n",
    "train_input_batches = [encode_sentences(batch, word2i) for batch in PT3_batched_sents]\n",
    "train_label_batches = [encode_labels(batch) for batch in PT3_batched_labs]\n",
    "\n",
    "validation_input_sents = [encode_sentences(batch, word2i) for batch in PT3_batched_sents_valid]\n",
    "validation_encoded_labels = [encode_labels(batch) for batch in PT3_batched_labs_valid]\n",
    "\n",
    "num_possible_labels = len(PT3Dict)\n",
    "model = ValuesClassifier(num_possible_labels, hidden_size, embeddings, word2i['<PAD>'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "\n",
    "possible_labels = PT3Dict.keys()\n",
    "\n",
    "output_model = training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    validation_input_sents,\n",
    "    validation_encoded_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "    possible_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414190ba",
   "metadata": {},
   "source": [
    "## Creating KNN (will try to see if i can get this model working)\n",
    "-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb44184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn base have not finished yet\n",
    "\"\"\"ML-kNN (Zhang & Zhou, 2005) is an adaptation of the kNN lazy learning algorithm for multi-label\n",
    "data. Actually this method follows the paradigm of PT4. In essence, ML-kNN uses the kNN algorithm\n",
    "independently for each label l: It finds the k nearest examples to the test instance and considers those\n",
    "that are labelled at least with l as positive and the rest as negative. What mainly differentiates this\n",
    "method from the application of the original kNN algorithm to the transformed problem using PT4 is\n",
    "the use of prior probabilities. ML-kNN has also the capability of producing a ranking of the labels as\n",
    "an output. \n",
    "\n",
    "\n",
    "Luo and Zincir-Heywood (2005) present two systems for multi-label document classification, which\n",
    "are also based on the kNN classifier. The main contribution of their work is on the pre-processing\n",
    "stage for the effective representation of documents. For the classification of a new instance, the\n",
    "systems initially find the k nearest examples. Then for every appearance of each label in each of these\n",
    "examples, they increase a corresponding counter for that label. Finally they output the N labels with\n",
    "the largest counts. N is chosen based on the number of labels of the instance. This is an inappropriate\n",
    "strategy for real-world use, where the number of labels of a new instance is unknown. \"\"\"\n",
    "\n",
    "class NearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
    "        # the nearest neighbor classifier simply remembers all the training data\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    def predict(self, X, distance='L1'):\n",
    "        \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        # lets make sure that the output type matches the input type\n",
    "        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
    "\n",
    "        # loop over all test rows\n",
    "        for i in range(num_test):\n",
    "            # find the nearest training image to the i'th test image\n",
    "            # using the L1 distance (sum of absolute value differences)\n",
    "            if distance == 'L1':\n",
    "                distances = np.sum(np.abs(self.Xtr - X[i,:]), axis=1)\n",
    "            # using the L2 distance (sum of absolute value differences)\n",
    "            if distance == 'L2':\n",
    "                distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis=1))\n",
    "            min_index = np.argmin(distances) # get the index with smallest distance\n",
    "            Ypred[i] = self.ytr[min_index] # predict the label of the nearest example\n",
    "\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c63bf396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/AnupamMicrosoft/PyTorch-Classification/blob/master/Linear%20Support%20Vector%20Machines.py\n",
    "from torch import nn\n",
    "import random\n",
    "class SVM_Loss(nn.modules.Module):    \n",
    "    def __init__(self):\n",
    "        super(SVM_Loss,self).__init__()\n",
    "    def forward(self, outputs, labels):\n",
    "         return torch.sum(torch.clamp(1 - outputs.t()*labels, min=0))/batch_size\n",
    "\n",
    "        \n",
    "        \n",
    "def runSVM(epochs,input_size,num_classes,train_input_batches, train_label_batches,validation_input_sents,\n",
    "    validation_encoded_labels):      \n",
    "    #SVM regression model and Loss\n",
    "    svm_model = nn.Linear(input_size,num_classes)\n",
    "    #model = LogisticRegression(input_size,num_classes)\n",
    "\n",
    "    ## Loss criteria and SGD optimizer\n",
    "    svm_loss_criteria = SVM_Loss()\n",
    "    #loss_criteria = nn.CrossEntropyLoss()  \n",
    "\n",
    "    #svm_optimizer = torch.optim.SGD(svm_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    optimizer = torch.optim.AdamW(svm_model.parameters(), LR)\n",
    "    \n",
    "    batches = list(zip(train_input_batches, train_label_batches))\n",
    "    random.shuffle(batches)\n",
    "    \n",
    "    \n",
    "    #total_step = len(batches)\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss_epoch = 0\n",
    "        batch_loss = 0\n",
    "        total_batches = 0\n",
    "        for features, labels in tqdm.tqdm(batches):\n",
    "            # Reshape images to (batch_size, input_size)\n",
    "            #images = images.reshape(-1, 28*28)                      \n",
    "            #labels = Variable(2*(labels.float()-0.5))\n",
    "\n",
    "            # Forward pass        \n",
    "            outputs = svm_model(features)           \n",
    "            loss_svm = svm_loss_criteria(outputs, labels)    \n",
    "\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss_svm.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "            #print(\"Model's parameter after the update:\")\n",
    "            #for param2 in svm_model.parameters():\n",
    "             #   print(param2)\n",
    "            total_batches += 1     \n",
    "            batch_loss += loss_svm.item()\n",
    "\n",
    "        avg_loss_epoch = batch_loss/total_batches\n",
    "        print ('Epoch [{}/{}], Averge Loss:for epoch[{}, {:.4f}]' \n",
    "                       .format(epoch+1, num_epochs, epoch+1, avg_loss_epoch ))\n",
    "    return svm_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3345f01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PT4_batched_sents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#encode\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_input_batches \u001b[38;5;241m=\u001b[39m [encode_sentences(batch, word2i) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mPT4_batched_sents\u001b[49m]\n\u001b[0;32m     11\u001b[0m train_label_batches \u001b[38;5;241m=\u001b[39m [encode_labels(batch) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m PT4_batched_labs]\n\u001b[0;32m     13\u001b[0m validation_input_sents \u001b[38;5;241m=\u001b[39m [encode_sentences(batch, word2i) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m PT4_batched_sents_valid]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PT4_batched_sents' is not defined"
     ]
    }
   ],
   "source": [
    "#__________________pt4 on svm  ______________#\n",
    "# You can increase epochs if need be\n",
    "epochs = 10\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.00001\n",
    "hidden_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "#encode\n",
    "train_input_batches = [encode_sentences(batch, word2i) for batch in PT4_batched_sents]\n",
    "train_label_batches = [encode_labels(batch) for batch in PT4_batched_labs]\n",
    "\n",
    "validation_input_sents = [encode_sentences(batch, word2i) for batch in PT4_batched_sents_valid]\n",
    "validation_encoded_labels = [encode_labels(batch) for batch in PT4_batched_labs_valid]\n",
    "\n",
    "num_possible_labels = len(PT4Dict)\n",
    "#model = ValuesClassifier(num_possible_labels, hidden_size, embeddings, word2i['<PAD>'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "\n",
    "possible_labels = PT4Dict.keys()\n",
    "input_size, _ = getSizeOfPT_Batched(train_input_batches,train_label_batches)\n",
    "\n",
    "runSVM(epochs,input_size,len(possible_labels),train_input_batches, train_label_batches,validation_input_sents,\n",
    "    validation_encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab431980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/426 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (8x4 and 426x47)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#model = ValuesClassifier(num_possible_labels, hidden_size, embeddings, word2i['<PAD>'])\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#optimizer = torch.optim.AdamW(model.parameters(), LR)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m possible_labels \u001b[38;5;241m=\u001b[39m PT3Dict\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mrunSVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_input_batches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpossible_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_input_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_input_sents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_encoded_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36mrunSVM\u001b[1;34m(epochs, input_size, num_classes, train_input_batches, train_label_batches, validation_input_sents, validation_encoded_labels)\u001b[0m\n\u001b[0;32m     33\u001b[0m total_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(batches):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Reshape images to (batch_size, input_size)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m#images = images.reshape(-1, 28*28)                      \u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m#labels = Variable(2*(labels.float()-0.5))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Forward pass        \u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43msvm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m           \n\u001b[0;32m     41\u001b[0m     loss_svm \u001b[38;5;241m=\u001b[39m svm_loss_criteria(outputs, labels)    \n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x4 and 426x47)"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "#_____________PT3 on SVM_________#\n",
    "epochs = 10\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.00001\n",
    "hidden_size = 256\n",
    "batch_size = 8\n",
    "\n",
    "#encode\n",
    "train_input_batches = [encode_sentences(batch, word2i) for batch in PT3_batched_sents]\n",
    "train_label_batches = [encode_labels(batch) for batch in PT3_batched_labs]\n",
    "\n",
    "validation_input_sents = [encode_sentences(batch, word2i) for batch in PT3_batched_sents_valid]\n",
    "validation_encoded_labels = [encode_labels(batch) for batch in PT3_batched_labs_valid]\n",
    "\n",
    "num_possible_labels = len(PT3Dict)\n",
    "#model = ValuesClassifier(num_possible_labels, hidden_size, embeddings, word2i['<PAD>'])\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "\n",
    "possible_labels = PT3Dict.keys()\n",
    "runSVM(epochs,len(train_input_batches),len(possible_labels),train_input_batches, train_label_batches,validation_input_sents,\n",
    "    validation_encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed1c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f11f32f5b63672a4c0988795b1526caad24c924b40cb7580ccb98e31ed131d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
